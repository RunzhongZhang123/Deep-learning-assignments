{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot configurations\n",
    "%matplotlib inline\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, Part 1: Backpropagation through time (BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Consider a simple RNN network shown in the following figure, where _wx, wh, b1, w, b2_ are the scalar parameters of the network. The loss function is the **mean squared error (MSE)**. Given input _(x1, x2) = (-1, 0)_, ground truth _(g1, g2) = (1, 0), h0 = 0, (wx, wh, b1, w, b2) = (2, 1, 1, 2, 1)_, compute _(dwx, dwh, db1, dw, db2)_, which are the gradients of loss with repect to 5 parameters _(wx, wh, b1, w, b2)_.\n",
    "\n",
    "![bptt](./img/bptt2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO:</span>\n",
    "\n",
    "Answer the above question. \n",
    "\n",
    "**First we calculate the forward path:**\n",
    "\n",
    "As we have: $$sigmoid(x)=\\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "h1 = sigmoid(wx\\*x1 + wh\\*h0 + b1) = sigmoid(2\\*-1 + 1\\*0 + 1) = sigmoid(-1) = 0.2689\n",
    "\n",
    "h2 = sigmoid(wx\\*x2 + wh\\*h1 + b1) = sigmoid(2\\*0 + 1\\*0.2689 + 1) = sigmoid(1.5) = 0.7806\n",
    "\n",
    "y1 = sigmoid(w\\*h1 + b2) = sigmoid(2\\*0.2689 + 1) = sigmoid(1.5378) = 0.8231\n",
    "\n",
    "y2 = sigmoid(w\\*h2 + b2) = sigmoid(2\\*0.7806 + 1) = sigmoid(2.5612) = 0.9283\n",
    "\n",
    "\\\\(loss = 0.5 *((y1 - g1)^2 + (y2 - g2)^2) = 0.5 * ((0.8231 - 1)^2 + (0.9283 - 0)^2) = 0.4465\\\\)\n",
    "\n",
    "\n",
    "**Second we calculate the backward path:**\n",
    "\n",
    "As we have: $$sigmoid'(x)=sigmoid(x)*(1-sigmoid(x))$$\n",
    "\n",
    "\\\\(\\frac{\\partial loss}{\\partial y1}=(y1-g1)=0.8231-1=-0.1769\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial loss}{\\partial y2}=(y2-g2)=0.9283\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial y1}{\\partial b2}=sigmoid(w*h1 + b2)*(1-sigmoid(w*h1 + b2))=0.8231*0.1769=0.1456\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial y2}{\\partial b2}=sigmoid(w*h2 + b2)*(1-sigmoid(w*h2 + b2))=0.9283*0.0717=0.0666\\\\)\n",
    "\n",
    "**Therefore, we have:** \\\\(db2=\\frac{\\partial loss}{\\partial y1}\\frac{\\partial y1}{\\partial b2}+ \\frac{\\partial loss}{\\partial y2}\\frac{\\partial y2}{\\partial b2}=-0.1769*0.1456+0.9283*0.0666=0.0361\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial y1}{\\partial w}=h1*sigmoid(w*h1 + b2)*(1-sigmoid(w*h1 + b2))=0.2689*0.8231*0.1769=0.0392\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial y2}{\\partial w}=h2*sigmoid(w*h2 + b2)*(1-sigmoid(w*h2 + b2))=0.7806*0.9283*0.0717=0.0520\\\\)\n",
    "\n",
    "**Therefore, we have:** \\\\(dw=\\frac{\\partial loss}{\\partial y1}*\\frac{\\partial y1}{\\partial w}+\\frac{\\partial loss}{\\partial y2}*\\frac{\\partial y2}{\\partial w}=-0.1769*0.0392+0.9283*0.0520=0.0413\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial y1}{h1}=w*sigmoid(w*h1 + b2)*(1-sigmoid(w*h1 + b2))=2*0.8231*0.1769=0.2912\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial h1}{b1}=sigmoid(wx*x1+wh*h0+b1)*(1-sigmoid(wx*x1+wh*h0+b1))=0.2689*0.7311=0.1966\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial loss}{\\partial y1}\\frac{\\partial y1}{\\partial h1}\\frac{\\partial h1}{\\partial b1}=-0.1769*0.2912*0.1966=-0.0101\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial y2}{h2}=w*sigmoid(w*h2 + b2)*(1-sigmoid(w*h2 + b2))=2*0.9283*0.0717=0.1331\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial h2}{b1}=sigmoid(wx*x2+wh*h1+b1)*(1-sigmoid(wx*x2+wh*h1+b1))=0.7806*0.2194=0.1712\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial h2}{h1}=wh*sigmoid(wx*x2+wh*h1+b1)*(1-sigmoid(wx*x2+wh*h1+b1))=1*0.7806*0.2194=0.1712\\\\)\n",
    "\n",
    "**Therefore, we have:** \\\\(db1=\\frac{\\partial loss}{\\partial y1}\\frac{\\partial y1}{\\partial h1}\\frac{\\partial h1}{\\partial b1} + \\frac{\\partial loss}{\\partial y2}\\frac{\\partial y2}{\\partial h2}(\\frac{\\partial h2}{\\partial b1} + \\frac{\\partial h2}{\\partial h1}\\frac{\\partial h1}{\\partial b1}) = -0.0101 + 0.9283*0.1331*(0.1712+0.1712*0.1966)=0.0152\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial h1}{wh}=h0*sigmoid(wx*x1+wh*h0+b1)*(1-sigmoid(wx*x1+wh*h0+b1))=0*0.2689*0.7311=0\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial h2}{wh}=h1*sigmoid(wx*x2+wh*h1+b1)*(1-sigmoid(wx*x2+wh*h1+b1))=0.2689*0.7806*0.2194=0.0461\\\\)\n",
    "\n",
    "**Therefore, we have:** \\\\(dwh=\\frac{\\partial loss}{\\partial y1}\\frac{\\partial y1}{\\partial h1}\\frac{\\partial h1}{\\partial wh} + \\frac{\\partial loss}{\\partial y2}\\frac{\\partial y2}{\\partial h2}(\\frac{\\partial h2}{\\partial wh} + \\frac{\\partial h2}{\\partial h1}\\frac{\\partial h1}{\\partial wh}) = 0 + 0.9283*0.1331*(0.0461+0)=0.0057\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial h1}{wx}=x1*sigmoid(wx*x1+wh*h0+b1)*(1-sigmoid(wx*x1+wh*h0+b1))=-1*0.2689*0.7311=-0.1966\\\\)\n",
    "\n",
    "\\\\(\\frac{\\partial h2}{wx}=x2*sigmoid(wx*x2+wh*h1+b1)*(1-sigmoid(wx*x2+wh*h1+b1))=0*0.7806*0.2194=0\\\\)\n",
    "\n",
    "**Therefore, we have:** \\\\(dwx=\\frac{\\partial loss}{\\partial y1}\\frac{\\partial y1}{\\partial h1}\\frac{\\partial h1}{\\partial wx} + \\frac{\\partial loss}{\\partial y2}\\frac{\\partial y2}{\\partial h2}(\\frac{\\partial h2}{\\partial wx} + \\frac{\\partial h2}{\\partial h1}\\frac{\\partial h1}{\\partial wx}) = -0.1769*0.2912*-0.1966 + 0.9283*0.1331*(0+0.1712*-0.1966)=0.0060\\\\)\n",
    "\n",
    "**In summary: db2=0.0361, dw=0.0413, db1=0.0152, dwh=0.0057, dwx=0.0060**\n",
    "\n",
    "\n",
    "* You can use LATEX to edit the equations, and Jupyter notebook can recognize basic LATEX syntax. Alternatively, you can edit equations in some other environment and then paste the screenshot of the equations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify by tensorflow\n",
      "dw = 0.0413, db2 = 0.0360, dwx = 0.0060, dwh = 0.0057, db1 = 0.0152\n"
     ]
    }
   ],
   "source": [
    "# use tensorflow to verify the answer.\n",
    "w = tf.Variable(2.0)\n",
    "b2 = tf.Variable(1.0)\n",
    "wx = tf.Variable(2.0)\n",
    "wh = tf.Variable(1.0)\n",
    "b1 = tf.Variable(1.0)\n",
    "\n",
    "h0 = tf.Variable(0.0)\n",
    "x = tf.placeholder(tf.float32, shape=(2,))\n",
    "g = tf.placeholder(tf.float32, shape=(2,))\n",
    "\n",
    "y = []\n",
    "h1 = tf.sigmoid(wx*x[0] + wh*h0 + b1)\n",
    "y.append(tf.sigmoid(w*h1 + b2))\n",
    "h2 = tf.sigmoid(wx*x[1] + wh*h1 + b1)\n",
    "y.append(tf.sigmoid(w*h2 + b2))\n",
    "\n",
    "\n",
    "loss = 0.5*(tf.square(g[0]-y[0]) + tf.square(g[1]-y[1]))\n",
    "\n",
    "dw, db2, dwx, dwh, db1 = tf.gradients(loss, [w, b2, wx, wh, b1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    dw_t, db2_t, dwx_t, dwh_t, db1_t = sess.run([dw, db2, dwx, dwh, db1],\n",
    "                                              feed_dict={x: np.asarray([-1.0,0.0]), g: np.asarray([1.0,0.0])})\n",
    "print(\"verify by tensorflow\")\n",
    "print(\"dw = {:.4f}, db2 = {:.4f}, dwx = {:.4f}, dwh = {:.4f}, db1 = {:.4f}\".format(dw_t, db2_t, dwx_t, dwh_t, db1_t))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1, Part 2: Use tensorflow modules to create XOR network\n",
    "\n",
    "In this part, you need to build and train an XOR network that can learn the XOR function. It is a very simple implementation of RNN and will give you an idea how RNN is built and how to train it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR network\n",
    "\n",
    "XOR network can learn the XOR $\\oplus$ function\n",
    "\n",
    "As shown in the figure below, and for instance, if input $(x0, x1, x2)$=(1,0,0), then output $(y1, y2, y3)$=(1,1,1). That is, $y_n = x_0\\oplus x_1 \\oplus ... \\oplus x_{n-1}$\n",
    "\n",
    "![xor_net](./img/xor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data set\n",
    "This function provides you the way to generate the data which is required for the training process. You should utilize it when building your training function for the GRU. Please read the source code for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.xor.dataset import create_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Demo) Build a network using a Tensorlow LSTMCell and GRUCell\n",
    "This section shows an example how to build a RNN network using an LSTM cell or GRU cell. Both LSTM and GRU cell are inbuilt classes in tensorflow which separately implement the real behavior of the LSTM and GRU neuron. \n",
    "\n",
    "Reference: \n",
    "1. [TensorFlow LSTM cell](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/LSTMCell)\n",
    "1. [TensorFlow GRU cell](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/GRUCell)\n",
    "2. [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1128 21:31:48.008954 140735790596992 deprecation.py:323] From <ipython-input-4-597affda235a>:5: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W1128 21:31:48.016242 140735790596992 deprecation.py:323] From <ipython-input-4-597affda235a>:16: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W1128 21:31:48.159185 140735790596992 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1128 21:31:48.175721 140735790596992 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1128 21:31:49.029762 140735790596992 deprecation.py:323] From <ipython-input-4-597affda235a>:20: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell\n",
    "\n",
    "# define LSTM cell\n",
    "lstm_units = 64\n",
    "cell = LSTMCell(lstm_units,num_proj=2,state_is_tuple=True)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input shape: (num_samples, seq_length, input_dimension)\n",
    "# Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1.\n",
    "input_data = tf.placeholder(tf.float32, shape=[None,None,1])\n",
    "output_data = tf.placeholder(tf.int64, shape=[None,None])\n",
    "\n",
    "# create LSTM network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "hidden, _ = tf.nn.dynamic_rnn(cell, input_data, dtype=tf.float32)\n",
    "\n",
    "# generate output from the hidden information\n",
    "output_shape = 2\n",
    "out = tf.layers.dense(hidden, output_shape)\n",
    "pred = tf.argmax(out, axis=2)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "\n",
    "# optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "correct_num = tf.equal(output_data,pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_num,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 21:31:49.976174 140735790596992 deprecation.py:323] From <ipython-input-5-e477353acb57>:5: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W1128 21:31:50.063004 140735790596992 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.rnn import GRUCell\n",
    "\n",
    "# define GRU cell\n",
    "gru_units = 64\n",
    "cell = GRUCell(gru_units)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input shape: (num_samples, seq_length, input_dimension)\n",
    "# Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1.\n",
    "input_data = tf.placeholder(tf.float32, shape=[None,None,1])\n",
    "output_data = tf.placeholder(tf.int64, shape=[None,None])\n",
    "\n",
    "# create GRU network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "hidden, _ = tf.nn.dynamic_rnn(cell, input_data, dtype=tf.float32)\n",
    "\n",
    "# generate output from the hidden information\n",
    "output_shape = 2\n",
    "out = tf.layers.dense(hidden, output_shape)\n",
    "pred = tf.argmax(out, axis=2)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "\n",
    "# optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "correct_num = tf.equal(output_data,pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_num,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "<span style='color:red'>TODO:</span> \n",
    "1. Build your training function for RNN (choose either LSTM or GRU); \n",
    "2. Plot the cost during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,loss = 0.9132660031318665, accuracy = 0.48980000615119934\n",
      "1,loss = 0.825751781463623, accuracy = 0.4700250029563904\n",
      "2,loss = 0.7270845770835876, accuracy = 0.43342500925064087\n",
      "3,loss = 0.6678993701934814, accuracy = 0.49877500534057617\n",
      "4,loss = 0.6637828946113586, accuracy = 0.6341000199317932\n",
      "5,loss = 0.6739504337310791, accuracy = 0.7551500201225281\n",
      "6,loss = 0.6795833110809326, accuracy = 0.5033249855041504\n",
      "7,loss = 0.665730357170105, accuracy = 0.7327499985694885\n",
      "8,loss = 0.6439501047134399, accuracy = 0.7402999997138977\n",
      "9,loss = 0.6160931587219238, accuracy = 0.7688249945640564\n",
      "10,loss = 0.5967678427696228, accuracy = 0.6763250231742859\n",
      "11,loss = 0.5827886462211609, accuracy = 0.7752000093460083\n",
      "12,loss = 0.630425214767456, accuracy = 0.6218249797821045\n",
      "13,loss = 0.6275697946548462, accuracy = 0.6643750071525574\n",
      "14,loss = 0.6546361446380615, accuracy = 0.6110749840736389\n",
      "15,loss = 0.6162014007568359, accuracy = 0.6258000135421753\n",
      "16,loss = 0.6110023260116577, accuracy = 0.6057249903678894\n",
      "17,loss = 0.5627396702766418, accuracy = 0.7439000010490417\n",
      "18,loss = 0.5708004832267761, accuracy = 0.7285500168800354\n",
      "19,loss = 0.5545714497566223, accuracy = 0.755299985408783\n",
      "20,loss = 0.5173597931861877, accuracy = 0.7509750127792358\n",
      "21,loss = 0.5032557249069214, accuracy = 0.7163249850273132\n",
      "22,loss = 0.4310728907585144, accuracy = 0.7914249897003174\n",
      "23,loss = 0.3935132920742035, accuracy = 0.8955249786376953\n",
      "24,loss = 0.3658854365348816, accuracy = 0.8811500072479248\n",
      "25,loss = 0.283234179019928, accuracy = 0.9441999793052673\n",
      "26,loss = 0.23995493352413177, accuracy = 0.9460999965667725\n",
      "27,loss = 0.17875516414642334, accuracy = 0.9781500101089478\n",
      "28,loss = 0.2200295627117157, accuracy = 0.9626500010490417\n",
      "29,loss = 0.30439063906669617, accuracy = 0.9152250289916992\n",
      "30,loss = 0.20361006259918213, accuracy = 0.9610249996185303\n",
      "31,loss = 0.07249284535646439, accuracy = 1.0\n",
      "32,loss = 0.3021143674850464, accuracy = 0.9140750169754028\n",
      "33,loss = 0.05179959535598755, accuracy = 1.0\n",
      "34,loss = 0.5213516354560852, accuracy = 0.8455749750137329\n",
      "35,loss = 0.28359588980674744, accuracy = 0.9324250221252441\n",
      "36,loss = 0.21141313016414642, accuracy = 0.9422749876976013\n",
      "37,loss = 0.060650914907455444, accuracy = 0.9847999811172485\n",
      "38,loss = 0.10367872565984726, accuracy = 0.9711750149726868\n",
      "39,loss = 0.1339038908481598, accuracy = 0.9641249775886536\n",
      "40,loss = 0.09921011328697205, accuracy = 0.9797250032424927\n",
      "41,loss = 0.0628599300980568, accuracy = 0.991225004196167\n",
      "42,loss = 0.05225077643990517, accuracy = 0.9957000017166138\n",
      "43,loss = 0.041722699999809265, accuracy = 0.99795001745224\n",
      "44,loss = 0.032513514161109924, accuracy = 0.998324990272522\n",
      "45,loss = 0.024674223735928535, accuracy = 1.0\n",
      "46,loss = 0.020788149908185005, accuracy = 1.0\n",
      "47,loss = 0.01953035034239292, accuracy = 1.0\n",
      "48,loss = 0.01896526850759983, accuracy = 1.0\n",
      "49,loss = 0.018318071961402893, accuracy = 1.0\n",
      "50,loss = 0.01734207011759281, accuracy = 1.0\n",
      "51,loss = 0.016161873936653137, accuracy = 1.0\n",
      "52,loss = 0.015119241550564766, accuracy = 1.0\n",
      "53,loss = 0.013613665476441383, accuracy = 1.0\n",
      "54,loss = 0.012240135110914707, accuracy = 1.0\n",
      "55,loss = 0.011335969902575016, accuracy = 1.0\n",
      "56,loss = 0.010754582472145557, accuracy = 1.0\n",
      "57,loss = 0.010395039804279804, accuracy = 1.0\n",
      "58,loss = 0.010129907168447971, accuracy = 1.0\n",
      "59,loss = 0.009817661717534065, accuracy = 1.0\n",
      "60,loss = 0.0093881506472826, accuracy = 1.0\n",
      "61,loss = 0.008885122835636139, accuracy = 1.0\n",
      "62,loss = 0.008387627080082893, accuracy = 1.0\n",
      "63,loss = 0.007941148243844509, accuracy = 1.0\n",
      "64,loss = 0.007555886637419462, accuracy = 1.0\n",
      "65,loss = 0.007225986570119858, accuracy = 1.0\n",
      "66,loss = 0.006942037958651781, accuracy = 1.0\n",
      "67,loss = 0.006695033051073551, accuracy = 1.0\n",
      "68,loss = 0.006477104965597391, accuracy = 1.0\n",
      "69,loss = 0.006281404756009579, accuracy = 1.0\n",
      "70,loss = 0.006102423649281263, accuracy = 1.0\n",
      "71,loss = 0.005935717839747667, accuracy = 1.0\n",
      "72,loss = 0.005777930375188589, accuracy = 1.0\n",
      "73,loss = 0.005626833997666836, accuracy = 1.0\n",
      "74,loss = 0.00548112578690052, accuracy = 1.0\n",
      "75,loss = 0.00534018175676465, accuracy = 1.0\n",
      "76,loss = 0.005203999113291502, accuracy = 1.0\n",
      "77,loss = 0.005072873085737228, accuracy = 1.0\n",
      "78,loss = 0.004947203677147627, accuracy = 1.0\n",
      "79,loss = 0.00482725165784359, accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: training\n",
    "X, y = create_dataset(5000)\n",
    "\n",
    "num_turn = 80\n",
    "losslist = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_turn):\n",
    "        _, l, acc= sess.run([optimizer, loss, accuracy], feed_dict={input_data: X, output_data: y})\n",
    "        losslist.append(l)\n",
    "        print('{},loss = {}, accuracy = {}'.format(i, l, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: plot loss history\n",
    "plt.plot(losslist)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 1, Part 3 :  Build your own LSTMCell\n",
    "In this part, you need to build your own LSTM cell to achieve the LSTM functionality. \n",
    "\n",
    "<span style=\"color:red\">TODO:</span> \n",
    "1. Finish class **MyLSTMCell** in utils/xor/rnn.py;\n",
    "2. Write the training function for your RNN;\n",
    "3. Plot the cost during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.xor.rnn import MyLSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate xor netowrk with your own LSTM cell\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Input shape: (num_samples,seq_length,input_dimension)\n",
    "#Output shape: (num_samples, output_ground_truth), and output_ground_truth is 0/1. \n",
    "input_data = tf.placeholder(tf.float32,shape=[None,None,1])\n",
    "output_data = tf.placeholder(tf.int64,shape=[None,None])\n",
    "\n",
    "# recreate xor netowrk with your own LSTM cell\n",
    "lstm_units = 64\n",
    "cell = MyLSTMCell(lstm_units,num_proj=2)\n",
    "\n",
    "# create GRU network: you can also choose other modules provided by tensorflow, like static_rnn etc.\n",
    "hidden, _ = tf.nn.dynamic_rnn(cell,input_data,dtype=tf.float32)\n",
    "\n",
    "# generate output from the hidden information\n",
    "output_shape = 2\n",
    "out = tf.layers.dense(hidden, output_shape)\n",
    "pred = tf.argmax(out,axis=2)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=output_data,logits=out))\n",
    "# optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "# accuracy\n",
    "correct = tf.equal(output_data,pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,loss = 1.7590659856796265, accuracy = 0.5130749940872192\n",
      "1,loss = 1.7644238471984863, accuracy = 0.4956499934196472\n",
      "2,loss = 1.4400146007537842, accuracy = 0.3843249976634979\n",
      "3,loss = 1.3183326721191406, accuracy = 0.3674750030040741\n",
      "4,loss = 1.2804447412490845, accuracy = 0.38782501220703125\n",
      "5,loss = 1.1732988357543945, accuracy = 0.31130000948905945\n",
      "6,loss = 1.0947517156600952, accuracy = 0.36887499690055847\n",
      "7,loss = 0.9268133044242859, accuracy = 0.38237500190734863\n",
      "8,loss = 0.805672824382782, accuracy = 0.38214999437332153\n",
      "9,loss = 0.7122290730476379, accuracy = 0.4434249997138977\n",
      "10,loss = 0.7065039277076721, accuracy = 0.4979250133037567\n",
      "11,loss = 0.785500705242157, accuracy = 0.4949750006198883\n",
      "12,loss = 0.7997347116470337, accuracy = 0.49592500925064087\n",
      "13,loss = 0.7919926643371582, accuracy = 0.492374986410141\n",
      "14,loss = 0.7687379717826843, accuracy = 0.5193250179290771\n",
      "15,loss = 0.7340282201766968, accuracy = 0.6446499824523926\n",
      "16,loss = 0.6979590654373169, accuracy = 0.6157000064849854\n",
      "17,loss = 0.6568986177444458, accuracy = 0.5565000176429749\n",
      "18,loss = 0.6172710657119751, accuracy = 0.5410500168800354\n",
      "19,loss = 0.6035863161087036, accuracy = 0.6064249873161316\n",
      "20,loss = 0.5918282270431519, accuracy = 0.6072250008583069\n",
      "21,loss = 0.5792796015739441, accuracy = 0.6051499843597412\n",
      "22,loss = 0.5670918822288513, accuracy = 0.6010000109672546\n",
      "23,loss = 0.5587221384048462, accuracy = 0.6357250213623047\n",
      "24,loss = 0.5519179105758667, accuracy = 0.6472749710083008\n",
      "25,loss = 0.5449673533439636, accuracy = 0.7161999940872192\n",
      "26,loss = 0.5380048155784607, accuracy = 0.7261499762535095\n",
      "27,loss = 0.5307807326316833, accuracy = 0.7376750111579895\n",
      "28,loss = 0.522512674331665, accuracy = 0.7046999931335449\n",
      "29,loss = 0.5122780203819275, accuracy = 0.7343249917030334\n",
      "30,loss = 0.500663161277771, accuracy = 0.7385500073432922\n",
      "31,loss = 0.49102216958999634, accuracy = 0.7130500078201294\n",
      "32,loss = 0.4812483489513397, accuracy = 0.7216249704360962\n",
      "33,loss = 0.4684169292449951, accuracy = 0.7227500081062317\n",
      "34,loss = 0.4496666491031647, accuracy = 0.7809749841690063\n",
      "35,loss = 0.42465752363204956, accuracy = 0.8084750175476074\n",
      "36,loss = 0.379335880279541, accuracy = 0.8505749702453613\n",
      "37,loss = 0.3031717836856842, accuracy = 0.9419249892234802\n",
      "38,loss = 0.24300363659858704, accuracy = 0.9625750184059143\n",
      "39,loss = 0.17152567207813263, accuracy = 0.9842249751091003\n",
      "40,loss = 0.14217834174633026, accuracy = 0.9875249862670898\n",
      "41,loss = 0.0908438116312027, accuracy = 1.0\n",
      "42,loss = 0.10759291052818298, accuracy = 0.990149974822998\n",
      "43,loss = 0.07388800382614136, accuracy = 0.9970999956130981\n",
      "44,loss = 0.05249089375138283, accuracy = 1.0\n",
      "45,loss = 0.04407024756073952, accuracy = 1.0\n",
      "46,loss = 0.04046367108821869, accuracy = 1.0\n",
      "47,loss = 0.03330251947045326, accuracy = 1.0\n",
      "48,loss = 0.027523456141352654, accuracy = 1.0\n",
      "49,loss = 0.024935245513916016, accuracy = 1.0\n",
      "50,loss = 0.02276485040783882, accuracy = 1.0\n",
      "51,loss = 0.02009093388915062, accuracy = 1.0\n",
      "52,loss = 0.017407534644007683, accuracy = 0.9995750188827515\n",
      "53,loss = 0.015559541061520576, accuracy = 1.0\n",
      "54,loss = 0.014586725272238255, accuracy = 1.0\n",
      "55,loss = 0.01420701015740633, accuracy = 1.0\n",
      "56,loss = 0.01372213289141655, accuracy = 1.0\n",
      "57,loss = 0.012855621054768562, accuracy = 1.0\n",
      "58,loss = 0.011936036869883537, accuracy = 1.0\n",
      "59,loss = 0.01120699755847454, accuracy = 1.0\n",
      "60,loss = 0.010743111371994019, accuracy = 1.0\n",
      "61,loss = 0.01037395466119051, accuracy = 1.0\n",
      "62,loss = 0.009898688644170761, accuracy = 1.0\n",
      "63,loss = 0.009386081248521805, accuracy = 1.0\n",
      "64,loss = 0.008975982666015625, accuracy = 1.0\n",
      "65,loss = 0.008673292584717274, accuracy = 1.0\n",
      "66,loss = 0.008428377099335194, accuracy = 1.0\n",
      "67,loss = 0.008202387019991875, accuracy = 1.0\n",
      "68,loss = 0.007974779233336449, accuracy = 1.0\n",
      "69,loss = 0.007740642409771681, accuracy = 1.0\n",
      "70,loss = 0.007506903260946274, accuracy = 1.0\n",
      "71,loss = 0.007285215891897678, accuracy = 1.0\n",
      "72,loss = 0.00708514079451561, accuracy = 1.0\n",
      "73,loss = 0.006910571362823248, accuracy = 1.0\n",
      "74,loss = 0.00675971619784832, accuracy = 1.0\n",
      "75,loss = 0.006626521237194538, accuracy = 1.0\n",
      "76,loss = 0.006502929609268904, accuracy = 1.0\n",
      "77,loss = 0.00638125604018569, accuracy = 1.0\n",
      "78,loss = 0.006257311906665564, accuracy = 1.0\n",
      "79,loss = 0.006132057867944241, accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: training\n",
    "X, y = create_dataset(5000)\n",
    "\n",
    "num_turn = 80\n",
    "losslist = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_turn):\n",
    "        _, l, acc= sess.run([optimizer, loss, accuracy], feed_dict={input_data: X, output_data: y})\n",
    "        losslist.append(l)\n",
    "        print('{},loss = {}, accuracy = {}'.format(i, l, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: plot loss history\n",
    "L = [i+1 for i in range(num_turn)]\n",
    "plt.plot(L, losslist)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
